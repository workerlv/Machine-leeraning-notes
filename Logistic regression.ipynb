{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0ieQbM+dPawlLKh/ZbkS7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Logistic regression"],"metadata":{"id":"ychvWtWSuZUM"}},{"cell_type":"markdown","source":["## numpy"],"metadata":{"id":"TjBFSgZDugHH"}},{"cell_type":"markdown","source":["With logistic regression we get probability from 0 to 1\n","* Approxiamtion: \n","$$ f(w, b) = wx + b $$\n","$$ \\hat{y} = h_{\\Theta}(x) = \\frac{1}{1+e^{-wx+b}} $$\n","* Sigmoid function:\n","$$ s(x) = \\frac{1}{1+e^{-x}} $$\n","\n","* Cost function (cross entropy):\n","$$ J(w, b) = J(Θ) = \\frac{1}{N}\\sum_{i=1}^{n}[y^ilog(h_{Θ}(x^{i}))+(1-y^{i})log(1-h_{Θ}(x^{i}))] $$\n","\n","* Update rules:\n","$$ w=w-\\alpha*dw $$\n","$$ b=b-\\alpha*db $$\n","where:\n","$$ \\alpha - learning\\; rate $$\n","\n","* Derivative:\n","$$ J'(Θ) = \\begin{bmatrix} \\frac{dJ}{dw}\\\\ \\frac{dJ}{db}\\end{bmatrix} = [....] =  \\begin{bmatrix} \\frac{1}{N}\\sum 2x_{i}(\\hat{y} - y_{i}) \\\\ \\frac{1}{N} \\sum 2(\\hat{y} - y_{i}) \\end{bmatrix} $$ \n"],"metadata":{"id":"PzXwh_CfupEv"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"aImvmn21uFEV","executionInfo":{"status":"ok","timestamp":1671041522886,"user_tz":-120,"elapsed":386,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets"]},{"cell_type":"markdown","source":["## very detailed"],"metadata":{"id":"mdCtgfde0Xlk"}},{"cell_type":"code","source":["def sigmoid_func(x):\n","    return 1 / (1 + np.exp(-x))"],"metadata":{"id":"8IEsNboP3Pwo","executionInfo":{"status":"ok","timestamp":1671042293942,"user_tz":-120,"elapsed":235,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Some sample data from sklearn\n","bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"],"metadata":{"id":"MpkuAl9449UQ","executionInfo":{"status":"ok","timestamp":1671042522479,"user_tz":-120,"elapsed":311,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape)\n","print(y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipAvN_I05s67","executionInfo":{"status":"ok","timestamp":1671042624184,"user_tz":-120,"elapsed":6,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"e23b28c0-731e-42ec-9073-1c8e70962969"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["(455, 30)\n","(455,)\n"]}]},{"cell_type":"code","source":["# init parameters\n","learning_rate = 0.0001\n","n_iters = 1000\n","n_samples, n_features = X.shape\n","\n","weights = np.zeros(n_features)\n","bias = 0"],"metadata":{"id":"8IfliwDX5UYm","executionInfo":{"status":"ok","timestamp":1671042786579,"user_tz":-120,"elapsed":377,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# gradient descent\n","for _ in range(n_iters):\n","    # approximate y with linear combination of weights and x, plus bias\n","    linear_model = np.dot(X_train, weights) + bias\n","    \n","    # apply sigmoid function\n","    y_predicted = sigmoid_func(linear_model)\n","\n","    # compute gradients\n","    dw = (1 / n_samples) * np.dot(X_train.T, (y_predicted - y_train))\n","    db = (1 / n_samples) * np.sum(y_predicted - y_train)\n","    \n","    # update parameters\n","    weights -= learning_rate * dw\n","    bias -= learning_rate * db"],"metadata":{"id":"_Ov-f2pH9Ny3","executionInfo":{"status":"ok","timestamp":1671050382404,"user_tz":-120,"elapsed":225,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["# predict\n","linear_model = np.dot(X_test, weights) + bias\n","y_predicted = sigmoid_func(linear_model)\n","y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n","predictions = np.array(y_predicted_cls)"],"metadata":{"id":"lJz-YxUv9twK","executionInfo":{"status":"ok","timestamp":1671050395131,"user_tz":-120,"elapsed":262,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# accuracy\n","accuracy = np.sum(y_test == predictions) / len(y_test)\n","\n","print(\"LR classification accuracy:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"55dQ0M6Y1qKY","executionInfo":{"status":"ok","timestamp":1671050456064,"user_tz":-120,"elapsed":246,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"0c625aa2-72e5-47b4-c479-b8501019a283"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["LR classification accuracy: 0.9210526315789473\n"]}]},{"cell_type":"markdown","source":["## clean version"],"metadata":{"id":"OknTaOB90PbN"}},{"cell_type":"code","source":["class LogisticRegression:\n","    def __init__(self, learning_rate=0.001, n_iters=1000):\n","        self.lr = learning_rate\n","        self.n_iters = n_iters\n","        self.weights = None\n","        self.bias = None\n","\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","\n","        # init parameters\n","        self.weights = np.zeros(n_features)\n","        self.bias = 0\n","\n","        # gradient descent\n","        for _ in range(self.n_iters):\n","            # approximate y with linear combination of weights and x, plus bias\n","            linear_model = np.dot(X, self.weights) + self.bias\n","            # apply sigmoid function\n","            y_predicted = self._sigmoid(linear_model)\n","\n","            # compute gradients\n","            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n","            db = (1 / n_samples) * np.sum(y_predicted - y)\n","            # update parameters\n","            self.weights -= self.lr * dw\n","            self.bias -= self.lr * db\n","\n","    def predict(self, X):\n","        linear_model = np.dot(X, self.weights) + self.bias\n","        y_predicted = self._sigmoid(linear_model)\n","        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n","        return np.array(y_predicted_cls)\n","\n","    def _sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n"],"metadata":{"id":"akBru9bP0SFx","executionInfo":{"status":"ok","timestamp":1671041507352,"user_tz":-120,"elapsed":4,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Testing\n","if __name__ == \"__main__\":\n","    # Imports\n","    from sklearn.model_selection import train_test_split\n","    from sklearn import datasets\n","\n","    def accuracy(y_true, y_pred):\n","        accuracy = np.sum(y_true == y_pred) / len(y_true)\n","        return accuracy\n","\n","    bc = datasets.load_breast_cancer()\n","    X, y = bc.data, bc.target\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=1234\n","    )\n","\n","    regressor = LogisticRegression(learning_rate=0.0001, n_iters=1000)\n","    regressor.fit(X_train, y_train)\n","    predictions = regressor.predict(X_test)\n","\n","    print(\"LR classification accuracy:\", accuracy(y_test, predictions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DWRbSjH0VE8","executionInfo":{"status":"ok","timestamp":1671041526768,"user_tz":-120,"elapsed":1032,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"6466ff75-e99b-4f43-e0a4-25146f1a8542"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["LR classification accuracy: 0.9298245614035088\n"]}]},{"cell_type":"markdown","source":["## sklearn"],"metadata":{"id":"P3Ci3Jtfc2mN"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dR1fGk9Xc40W","executionInfo":{"status":"ok","timestamp":1671051845064,"user_tz":-120,"elapsed":367,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"5b52f800-5d08-4968-9029-9a3c2aa1e760"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9733333333333334"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["bc_ = datasets.load_breast_cancer()\n","X_, y_ = bc_.data, bc_.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=1234)"],"metadata":{"id":"_RhbmjP5dDTJ","executionInfo":{"status":"ok","timestamp":1671051926403,"user_tz":-120,"elapsed":349,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["clf = LogisticRegression(random_state=0)\n","clf.fit(X_train, y_train)\n","y_hat = clf.predict(X_test)\n","\n","clf.predict_proba(X_test)\n","clf.score(X_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z82ygZ8DdQ5_","executionInfo":{"status":"ok","timestamp":1671052320817,"user_tz":-120,"elapsed":262,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"effc491a-d72f-477f-c7fe-df8ea169a094"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9385964912280702"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["accuracy_ = np.sum(y_test == y_hat) / len(y_test)\n","\n","print(\"LR classification accuracy:\", accuracy_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnlkfL_Gdirt","executionInfo":{"status":"ok","timestamp":1671052312119,"user_tz":-120,"elapsed":239,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"35e66faf-e313-444d-d7ec-0271c385415c"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["LR classification accuracy: 0.9385964912280702\n"]}]}]}