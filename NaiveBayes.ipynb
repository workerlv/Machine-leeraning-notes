{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMqmfrbidOTN6J24iFffMxQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Naive Bayes"],"metadata":{"id":"qH5ai0QQk5qj"}},{"cell_type":"markdown","source":["Bayes Theorem:\n","$$ P(A|B) = \\frac{P(B|A) * P(A)}{P(B)} $$\n","In our case:\n","$$ P(y|X) = \\frac{P(X|y) * P(y)}{P(X)} $$\n","with feature vector X:\n","$$ X = (x_{1}, x_{2}, x_{3}....x_{n}) $$\n","Assume that all features are mutually independent\n","$$ P(y|X) = \\frac{P(x_{1}|y) + P(x_{2}|y)*..... P(x_{n}|y)* P(y)}{P(X)} $$\n","Select class with highes probabilty:\n","$$ y = argmax_{y} P(y|X) = \\frac{P(x_{1}|y) + P(x_{2}|y)*..... P(x_{n}|y)* P(y)}{P(X)} $$\n","$$ y = argmax_{y} P(x_{1}|y) + P(x_{2}|y)*..... P(x_{n}|y)* P(y) $$\n","$$ y = argmax_{y} log(P(x_{1}|y)) + log(P(x_{2}|y))*..... log(P(x_{n}|y))* log(P(y)) $$\n","Prior probability P(y): frequency\n","\n","Class conditional probability \n","$$ P(X_i|y) $$\n","\n","$$ P(x_{i}|y) = \\frac{1}{\\sqrt{2πσ_{y}^{2}}} * exp(- \\frac{(x_{i} - μ_{y})^{2}}{2σ_{y}^{2}}) $$"],"metadata":{"id":"0hzaU11jlDRg"}},{"cell_type":"markdown","source":[],"metadata":{"id":"Y48vmVg5k9FZ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"w538P_bvkEde","executionInfo":{"status":"ok","timestamp":1671139314728,"user_tz":-120,"elapsed":3,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","source":["## very detailed"],"metadata":{"id":"_psqfstGqmRw"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn import datasets"],"metadata":{"id":"HbClr_NTqrC-","executionInfo":{"status":"ok","timestamp":1671139555978,"user_tz":-120,"elapsed":389,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Some sample data from sklearn\n","X, y = datasets.make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=123)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"],"metadata":{"id":"VMwhTT-5rcKQ","executionInfo":{"status":"ok","timestamp":1671140060425,"user_tz":-120,"elapsed":260,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape)\n","print(y_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"610EzxperprP","executionInfo":{"status":"ok","timestamp":1671140063066,"user_tz":-120,"elapsed":263,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"58063077-513c-4219-b7ae-c658365bfb00"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["(800, 10)\n","(800,)\n"]}]},{"cell_type":"code","source":["# init parameters\n","n_samples, n_features = X.shape\n","classes_ = np.unique(y)\n","n_classes = len(np.unique(y))"],"metadata":{"id":"-y_0HppOrscO","executionInfo":{"status":"ok","timestamp":1671140063830,"user_tz":-120,"elapsed":2,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# calculate mean, var, and prior for each class\n","mean_ = np.zeros((n_classes, n_features), dtype=np.float64)\n","var_ = np.zeros((n_classes, n_features), dtype=np.float64)\n","priors_ = np.zeros(n_classes, dtype=np.float64)\n","\n","for idx, c in enumerate(classes_):\n","    X_c = X_train[y_train == c]\n","    mean_[idx, :] = X_c.mean(axis=0)\n","    var_[idx, :] = X_c.var(axis=0)\n","    priors_[idx] = X_c.shape[0] / float(n_samples)"],"metadata":{"id":"_si6o6bzr8_7","executionInfo":{"status":"ok","timestamp":1671140079698,"user_tz":-120,"elapsed":388,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# predict\n","y_pred = []\n","\n","for x in X_test:\n","  posteriors = []\n","\n","  for idx, c in enumerate(classes_):\n","    prior = np.log(priors_[idx])\n","    \n","    mean = mean_[idx]\n","    var = var_[idx]\n","    numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n","    denominator = np.sqrt(2 * np.pi * var)\n","    posterior = np.sum(np.log(numerator / denominator))\n","\n","    posterior = prior + posterior\n","    posteriors.append(posterior)\n","\n","  y_pred.append(classes_[np.argmax(posteriors)])"],"metadata":{"id":"Eh3eYJ6Ftkln","executionInfo":{"status":"ok","timestamp":1671141830820,"user_tz":-120,"elapsed":237,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["accuracy = np.sum(y_test == y_pred) / len(y_test)\n","print(\"Naive Bayes classification accuracy\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdVuMDsVxmjR","executionInfo":{"status":"ok","timestamp":1671141833273,"user_tz":-120,"elapsed":364,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"1e8c4460-f017-4122-8835-8cc489cc475c"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes classification accuracy 0.965\n"]}]},{"cell_type":"markdown","source":["## clean version"],"metadata":{"id":"35UoThs0qZGa"}},{"cell_type":"code","source":["class NaiveBayes:\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","        self._classes = np.unique(y)\n","        n_classes = len(self._classes)\n","\n","        # calculate mean, var, and prior for each class\n","        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._priors = np.zeros(n_classes, dtype=np.float64)\n","\n","        for idx, c in enumerate(self._classes):\n","            X_c = X[y == c]\n","            self._mean[idx, :] = X_c.mean(axis=0)\n","            self._var[idx, :] = X_c.var(axis=0)\n","            self._priors[idx] = X_c.shape[0] / float(n_samples)\n","\n","    def predict(self, X):\n","        y_pred = [self._predict(x) for x in X]\n","        return np.array(y_pred)\n","\n","    def _predict(self, x):\n","        posteriors = []\n","\n","        # calculate posterior probability for each class\n","        for idx, c in enumerate(self._classes):\n","            prior = np.log(self._priors[idx])\n","            posterior = np.sum(np.log(self._pdf(idx, x)))\n","            posterior = prior + posterior\n","            posteriors.append(posterior)\n","\n","        # return class with highest posterior probability\n","        return self._classes[np.argmax(posteriors)]\n","\n","    def _pdf(self, class_idx, x):\n","        mean = self._mean[class_idx]\n","        var = self._var[class_idx]\n","        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n","        denominator = np.sqrt(2 * np.pi * var)\n","        return numerator / denominator"],"metadata":{"id":"dSufUPl0qcpZ","executionInfo":{"status":"ok","timestamp":1671139315084,"user_tz":-120,"elapsed":3,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Testing\n","if __name__ == \"__main__\":\n","    # Imports\n","    from sklearn.model_selection import train_test_split\n","    from sklearn import datasets\n","\n","    def accuracy(y_true, y_pred):\n","        accuracy = np.sum(y_true == y_pred) / len(y_true)\n","        return accuracy\n","\n","    X, y = datasets.make_classification(\n","        n_samples=1000, n_features=10, n_classes=2, random_state=123\n","    )\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=0.2, random_state=123\n","    )\n","\n","    nb = NaiveBayes()\n","    nb.fit(X_train, y_train)\n","    predictions = nb.predict(X_test)\n","\n","    print(\"Naive Bayes classification accuracy\", accuracy(y_test, predictions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNIb6C81qdqi","executionInfo":{"status":"ok","timestamp":1671139318679,"user_tz":-120,"elapsed":1415,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"8f409af6-691c-45f4-8b6a-b39961fc4b97"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes classification accuracy 0.965\n"]}]},{"cell_type":"markdown","source":["## sklearn"],"metadata":{"id":"9Md9yD8u0Mo7"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","X, y = datasets.make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=123)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n","\n","gnb = GaussianNB()\n","y_pred = gnb.fit(X_train, y_train).predict(X_test)\n","print(\"Number of mislabeled points out of a total %d points : %d\"\n","      % (X_test.shape[0], (y_test != y_pred).sum()))\n","\n","print(\"Naive Bayes classification accuracy\", accuracy_score(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GM3T4YCt0OaT","executionInfo":{"status":"ok","timestamp":1671142007559,"user_tz":-120,"elapsed":372,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"a0c601e9-8e2c-4f1e-eb6a-cdcee60dffa2"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of mislabeled points out of a total 200 points : 7\n","Naive Bayes classification accuracy 0.965\n"]}]}]}