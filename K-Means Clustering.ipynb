{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTqqsyS0N6bm9tlUUTozkN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# K-Means Clustering"],"metadata":{"id":"PBSGSgMn9IPR"}},{"cell_type":"markdown","source":["K-means clustering is a type of algorithm used to group together similar data points. It is commonly used in data science and machine learning. The process works by dividing a dataset into K number of clusters, with each cluster containing data points that are similar to each other.\n","\n","The algorithm works by first randomly selecting K initial points as the \"centers\" of the clusters. Then, each data point in the dataset is assigned to the closest center. The centers are then recalculated based on the average of all the data points assigned to each cluster. This process is repeated until the centers no longer move significantly or a maximum number of iterations is reached.\n","\n","The resulting clusters are made up of data points that are similar to each other and different from those in other clusters. K-means clustering can be useful in many applications, such as grouping customers with similar preferences or clustering images with similar features."],"metadata":{"id":"oOyi12nR9NF4"}},{"cell_type":"markdown","source":["## Numpy"],"metadata":{"id":"R6OHPgBPCofG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tEPlzMVP9BY6"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","np.random.seed(42)\n","\n","\n","def euclidean_distance(x1, x2):\n","    return np.sqrt(np.sum((x1 - x2) ** 2))\n","\n","\n","class KMeans:\n","    def __init__(self, K=5, max_iters=100, plot_steps=False):\n","        self.K = K\n","        self.max_iters = max_iters\n","        self.plot_steps = plot_steps\n","\n","        # list of sample indices for each cluster\n","        self.clusters = [[] for _ in range(self.K)]\n","        # the centers (mean feature vector) for each cluster\n","        self.centroids = []\n","\n","    def predict(self, X):\n","        self.X = X\n","        self.n_samples, self.n_features = X.shape\n","\n","        # initialize\n","        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n","        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n","\n","        # Optimize clusters\n","        for _ in range(self.max_iters):\n","            # Assign samples to closest centroids (create clusters)\n","            self.clusters = self._create_clusters(self.centroids)\n","\n","            if self.plot_steps:\n","                self.plot()\n","\n","            # Calculate new centroids from the clusters\n","            centroids_old = self.centroids\n","            self.centroids = self._get_centroids(self.clusters)\n","\n","            # check if clusters have changed\n","            if self._is_converged(centroids_old, self.centroids):\n","                break\n","\n","            if self.plot_steps:\n","                self.plot()\n","\n","        # Classify samples as the index of their clusters\n","        return self._get_cluster_labels(self.clusters)\n","\n","    def _get_cluster_labels(self, clusters):\n","        # each sample will get the label of the cluster it was assigned to\n","        labels = np.empty(self.n_samples)\n","\n","        for cluster_idx, cluster in enumerate(clusters):\n","            for sample_index in cluster:\n","                labels[sample_index] = cluster_idx\n","        return labels\n","\n","    def _create_clusters(self, centroids):\n","        # Assign the samples to the closest centroids to create clusters\n","        clusters = [[] for _ in range(self.K)]\n","        for idx, sample in enumerate(self.X):\n","            centroid_idx = self._closest_centroid(sample, centroids)\n","            clusters[centroid_idx].append(idx)\n","        return clusters\n","\n","    def _closest_centroid(self, sample, centroids):\n","        # distance of the current sample to each centroid\n","        distances = [euclidean_distance(sample, point) for point in centroids]\n","        closest_index = np.argmin(distances)\n","        return closest_index\n","\n","    def _get_centroids(self, clusters):\n","        # assign mean value of clusters to centroids\n","        centroids = np.zeros((self.K, self.n_features))\n","        for cluster_idx, cluster in enumerate(clusters):\n","            cluster_mean = np.mean(self.X[cluster], axis=0)\n","            centroids[cluster_idx] = cluster_mean\n","        return centroids\n","\n","    def _is_converged(self, centroids_old, centroids):\n","        # distances between each old and new centroids, fol all centroids\n","        distances = [\n","            euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)\n","        ]\n","        return sum(distances) == 0\n","\n","    def plot(self):\n","        fig, ax = plt.subplots(figsize=(12, 8))\n","\n","        for i, index in enumerate(self.clusters):\n","            point = self.X[index].T\n","            ax.scatter(*point)\n","\n","        for point in self.centroids:\n","            ax.scatter(*point, marker=\"x\", color=\"black\", linewidth=2)\n","\n","        plt.show()\n","\n","\n","# Testing\n","if __name__ == \"__main__\":\n","    from sklearn.datasets import make_blobs\n","\n","    X, y = make_blobs(\n","        centers=3, n_samples=500, n_features=2, shuffle=True, random_state=40\n","    )\n","    print(X.shape)\n","\n","    clusters = len(np.unique(y))\n","    print(clusters)\n","\n","    k = KMeans(K=clusters, max_iters=150, plot_steps=True)\n","    y_pred = k.predict(X)\n","\n","    k.plot()"]},{"cell_type":"markdown","source":["## Sklearn"],"metadata":{"id":"6W8A8xq6DGTt"}},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","import numpy as np\n","from sklearn.datasets import make_blobs\n","\n","X, y = make_blobs(\n","    centers=3, n_samples=500, n_features=2, shuffle=True, random_state=40\n",")\n","print(X.shape)\n","\n","kmeans = KMeans(n_clusters=len(np.unique(y)), random_state=0).fit(X)\n","y_pred = kmeans.predict(X)\n","\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qjJ077YXFKuv","executionInfo":{"status":"ok","timestamp":1678532604997,"user_tz":-120,"elapsed":234,"user":{"displayName":"Arturs Vitins","userId":"16068103353402116777"}},"outputId":"664238eb-3de3-45e2-d063-6e22766e5569"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(500, 2)\n","[1 0 2 2 0 0 1 1 1 1 0 0 2 1 0 2 0 0 1 2 1 0 0 0 1 1 1 0 1 2 0 1 0 2 2 1 0\n"," 2 1 1 0 1 0 0 2 2 2 2 0 0 2 2 1 2 2 0 2 0 2 0 1 2 0 1 2 1 1 0 0 2 2 1 0 2\n"," 1 0 0 1 0 2 1 2 2 0 2 0 1 2 2 1 1 1 0 1 2 0 2 1 2 0 2 0 2 0 0 1 0 0 0 2 2\n"," 2 0 0 0 1 0 1 1 0 2 2 0 2 0 1 2 0 0 0 0 2 2 2 0 1 0 2 0 0 1 2 0 1 1 0 1 1\n"," 1 1 0 0 0 0 1 2 2 2 1 2 2 1 2 2 0 1 2 2 0 0 1 2 0 2 2 2 2 2 2 1 0 2 0 1 0\n"," 1 2 1 0 0 2 2 1 0 2 2 1 2 2 1 1 2 0 0 0 1 1 1 2 0 0 0 0 1 2 1 0 2 1 1 2 0\n"," 2 2 2 0 0 2 2 1 2 0 1 0 2 2 0 0 1 1 2 2 1 1 1 2 2 1 1 2 1 2 0 0 2 2 1 2 0\n"," 0 0 0 0 0 1 0 2 2 1 0 1 1 1 2 1 2 0 2 0 2 0 1 1 2 2 2 0 1 1 2 2 1 0 0 1 1\n"," 1 2 0 0 2 2 0 2 1 0 0 2 1 1 0 0 0 1 0 2 2 0 1 1 0 1 1 1 1 0 1 2 0 1 1 2 2\n"," 0 1 1 2 2 2 1 2 0 1 0 2 1 2 0 0 1 0 2 2 2 0 2 1 2 1 1 1 1 1 1 1 0 1 1 1 0\n"," 0 2 0 0 2 1 1 0 0 0 2 1 1 2 0 1 0 0 0 0 1 1 0 2 2 0 0 1 2 0 2 2 1 1 0 2 2\n"," 2 0 1 2 2 1 0 2 0 0 1 1 1 2 1 1 1 2 0 2 0 2 0 1 0 1 0 0 0 2 2 2 2 0 0 1 2\n"," 0 1 2 1 2 2 2 2 2 0 1 1 1 1 1 1 0 0 0 2 0 1 1 1 2 2 1 2 1 1 2 0 1 2 1 1 1\n"," 0 1 1 0 1 2 1 1 0 0 1 0 2 1 1 1 0 2 1]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n","  warnings.warn(\n"]}]}]}